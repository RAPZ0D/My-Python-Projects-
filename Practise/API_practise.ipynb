{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retriving the data and storing in local folder \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from the FakeStore API successfully retrieved and stored in 'fakestore_products.json'.\n"
     ]
    }
   ],
   "source": [
    "api_url = \"https://fakestoreapi.com/products\"  \n",
    "try:\n",
    "    response = requests.get(api_url)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    local_file_path = \"fakestore_products.json\"\n",
    "    with open(local_file_path, \"w\") as file:\n",
    "        json.dump(data, file)\n",
    "\n",
    "    print(f\"Data from the FakeStore API successfully retrieved and stored in '{local_file_path}'.\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error: {e}\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error decoding JSON response: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API key authentication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather data successfully retrieved and stored in 'weather_data.json'.\n"
     ]
    }
   ],
   "source": [
    "api_key = \"6d74e9353e3ab512e6405030fd4f8f75\"\n",
    "api_url = \"https://api.openweathermap.org/data/2.5/weather\"\n",
    "\n",
    "# Specify the city and country code for the weather data you want to retrieve\n",
    "city = \"New York\"\n",
    "country_code = \"US\"\n",
    "\n",
    "# Construct the API request URL\n",
    "params = {\n",
    "    \"q\": f\"{city},{country_code}\",\n",
    "    \"appid\": api_key,\n",
    "    \"units\": \"metric\"  # You can change this to \"imperial\" for Fahrenheit\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Make a GET request to the OpenWeatherMap API\n",
    "    response = requests.get(api_url, params=params)\n",
    "    response.raise_for_status()  # Raise an exception for HTTP errors (4xx and 5xx status codes)\n",
    "\n",
    "    # Save the JSON response directly to a local file\n",
    "    with open(\"weather_data.json\", \"w\") as file:\n",
    "        json.dump(response.json(), file)\n",
    "\n",
    "    print(\"Weather data successfully retrieved and stored in 'weather_data.json'.\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error: {e}\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error decoding JSON response: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"coord\": {\n",
      "        \"lon\": -74.006,\n",
      "        \"lat\": 40.7143\n",
      "    },\n",
      "    \"weather\": [\n",
      "        {\n",
      "            \"id\": 804,\n",
      "            \"main\": \"Clouds\",\n",
      "            \"description\": \"overcast clouds\",\n",
      "            \"icon\": \"04n\"\n",
      "        }\n",
      "    ],\n",
      "    \"base\": \"stations\",\n",
      "    \"main\": {\n",
      "        \"temp\": 13.51,\n",
      "        \"feels_like\": 12.35,\n",
      "        \"temp_min\": 9.58,\n",
      "        \"temp_max\": 15.55,\n",
      "        \"pressure\": 1010,\n",
      "        \"humidity\": 55\n",
      "    },\n",
      "    \"visibility\": 10000,\n",
      "    \"wind\": {\n",
      "        \"speed\": 3.6,\n",
      "        \"deg\": 250\n",
      "    },\n",
      "    \"clouds\": {\n",
      "        \"all\": 100\n",
      "    },\n",
      "    \"dt\": 1696896149,\n",
      "    \"sys\": {\n",
      "        \"type\": 2,\n",
      "        \"id\": 2008101,\n",
      "        \"country\": \"US\",\n",
      "        \"sunrise\": 1696849218,\n",
      "        \"sunset\": 1696890366\n",
      "    },\n",
      "    \"timezone\": -14400,\n",
      "    \"id\": 5128581,\n",
      "    \"name\": \"New York\",\n",
      "    \"cod\": 200\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "json_file_path = \"weather_data.json\"\n",
    "try:\n",
    "    with open(json_file_path, \"r\") as file:\n",
    "        weather_data = json.load(file)\n",
    "        print(json.dumps(weather_data, indent=4))\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"File '{json_file_path}' not found.\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error decoding JSON data: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing the data in the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather data successfully stored in 'weather_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "api_key = \"6d74e9353e3ab512e6405030fd4f8f75\"\n",
    "api_url = \"https://api.openweathermap.org/data/2.5/weather\"\n",
    "\n",
    "# Define the list of cities and their country codes\n",
    "cities = [(\"New York\", \"US\"), (\"London\", \"GB\"), (\"Paris\", \"FR\"), (\"Tokyo\", \"JP\"), (\"Sydney\", \"AU\")]\n",
    "\n",
    "# Initialize an empty list to store weather data\n",
    "weather_data_list = []\n",
    "\n",
    "for city, country_code in cities:\n",
    "    params = {\n",
    "        \"q\": f\"{city},{country_code}\",\n",
    "        \"appid\": api_key,\n",
    "        \"units\": \"metric\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(api_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        weather_data_list.append(response.json())\n",
    "\n",
    "    except (requests.exceptions.RequestException, json.JSONDecodeError) as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Define the path to the CSV file\n",
    "csv_file_path = \"weather_data.csv\"\n",
    "\n",
    "# Write the weather data to a CSV file\n",
    "if weather_data_list:\n",
    "    fieldnames = [\"City\", \"Country\", \"Temperature (°C)\", \"Humidity (%)\", \"Weather Description\"]\n",
    "    \n",
    "    with open(csv_file_path, \"w\", newline=\"\") as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        for data in weather_data_list:\n",
    "            writer.writerow({\n",
    "                \"City\": data[\"name\"],\n",
    "                \"Country\": data[\"sys\"][\"country\"],\n",
    "                \"Temperature (°C)\": data[\"main\"][\"temp\"],\n",
    "                \"Humidity (%)\": data[\"main\"][\"humidity\"],\n",
    "                \"Weather Description\": data[\"weather\"][0][\"description\"]\n",
    "            })\n",
    "\n",
    "    print(f\"Weather data successfully stored in '{csv_file_path}'.\")\n",
    "else:\n",
    "    print(\"No weather data retrieved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       City Country  Temperature (°C)  Humidity (%) Weather Description\n",
      "0  New York      US             13.50            55     overcast clouds\n",
      "1    London      GB             15.24            88     overcast clouds\n",
      "2     Paris      FR             15.38            77           clear sky\n",
      "3     Tokyo      JP             20.10            87       broken clouds\n",
      "4    Sydney      AU             20.08            70       broken clouds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('weather_data.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Streaming API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted nationality: NG (Probability: 0.243)\n"
     ]
    }
   ],
   "source": [
    "user_name = input(\"Enter your name: \")\n",
    "\n",
    "# Define the API URL\n",
    "api_url = f\"https://api.nationalize.io?name={user_name}\"\n",
    "\n",
    "try:\n",
    "    # Make a GET request to the API\n",
    "    response = requests.get(api_url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # Extract the nationality prediction (if available)\n",
    "    nationality_data = response.json().get('country', [])\n",
    "    if nationality_data:\n",
    "        nationality, probability = nationality_data[0]['country_id'], nationality_data[0]['probability']\n",
    "        print(f\"Predicted nationality: {nationality} (Probability: {probability})\")\n",
    "    else:\n",
    "        print(\"No nationality prediction available for this name.\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error: {e}\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error decoding JSON response: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "Forbidden",
     "evalue": "403 Forbidden\n453 - You currently have access to a subset of Twitter API v2 endpoints and limited v1.1 endpoints (e.g. media post, oauth) only. If you need access to this endpoint, you may need a different access level. You can learn more here: https://developer.twitter.com/en/portal/product",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mForbidden\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/joelmendonsa/Desktop/Big data programming/Practise/API_practise.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joelmendonsa/Desktop/Big%20data%20programming/Practise/API_practise.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m num_tweets \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joelmendonsa/Desktop/Big%20data%20programming/Practise/API_practise.ipynb#X26sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m tweets \u001b[39m=\u001b[39m tweepy\u001b[39m.\u001b[39mCursor(api\u001b[39m.\u001b[39msearch_tweets, q\u001b[39m=\u001b[39mkeyword, tweet_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mextended\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mitems(num_tweets)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/joelmendonsa/Desktop/Big%20data%20programming/Practise/API_practise.ipynb#X26sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mfor\u001b[39;00m tweet \u001b[39min\u001b[39;00m tweets:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joelmendonsa/Desktop/Big%20data%20programming/Practise/API_practise.ipynb#X26sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUser: @\u001b[39m\u001b[39m{\u001b[39;00mtweet\u001b[39m.\u001b[39muser\u001b[39m.\u001b[39mscreen_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joelmendonsa/Desktop/Big%20data%20programming/Practise/API_practise.ipynb#X26sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTweet: \u001b[39m\u001b[39m{\u001b[39;00mtweet\u001b[39m.\u001b[39mfull_text\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Big data programming/newenv/lib/python3.10/site-packages/tweepy/cursor.py:86\u001b[0m, in \u001b[0;36mBaseIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 86\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext()\n",
      "File \u001b[0;32m~/Desktop/Big data programming/newenv/lib/python3.10/site-packages/tweepy/cursor.py:286\u001b[0m, in \u001b[0;36mItemIterator.next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_page \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpage_index \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_page) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Reached end of current page, get the next page...\u001b[39;00m\n\u001b[0;32m--> 286\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_page \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpage_iterator)\n\u001b[1;32m    287\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_page) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    288\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_page \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpage_iterator)\n",
      "File \u001b[0;32m~/Desktop/Big data programming/newenv/lib/python3.10/site-packages/tweepy/cursor.py:86\u001b[0m, in \u001b[0;36mBaseIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 86\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext()\n",
      "File \u001b[0;32m~/Desktop/Big data programming/newenv/lib/python3.10/site-packages/tweepy/cursor.py:167\u001b[0m, in \u001b[0;36mIdIterator.next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 167\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmethod(max_id\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_id, parser\u001b[39m=\u001b[39;49mRawParser(), \u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs)\n\u001b[1;32m    169\u001b[0m     model \u001b[39m=\u001b[39m ModelParser()\u001b[39m.\u001b[39mparse(\n\u001b[1;32m    170\u001b[0m         data, api \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmethod\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m,\n\u001b[1;32m    171\u001b[0m         payload_list\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmethod\u001b[39m.\u001b[39mpayload_list,\n\u001b[1;32m    172\u001b[0m         payload_type\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmethod\u001b[39m.\u001b[39mpayload_type\n\u001b[1;32m    173\u001b[0m     )\n\u001b[1;32m    174\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmethod\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mparser\u001b[39m.\u001b[39mparse(\n\u001b[1;32m    175\u001b[0m         data, api \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmethod\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m,\n\u001b[1;32m    176\u001b[0m         payload_list\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmethod\u001b[39m.\u001b[39mpayload_list,\n\u001b[1;32m    177\u001b[0m         payload_type\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmethod\u001b[39m.\u001b[39mpayload_type\n\u001b[1;32m    178\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/Big data programming/newenv/lib/python3.10/site-packages/tweepy/api.py:33\u001b[0m, in \u001b[0;36mpagination.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(method)\n\u001b[1;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 33\u001b[0m     \u001b[39mreturn\u001b[39;00m method(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/Big data programming/newenv/lib/python3.10/site-packages/tweepy/api.py:46\u001b[0m, in \u001b[0;36mpayload.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m kwargs[\u001b[39m'\u001b[39m\u001b[39mpayload_list\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m payload_list\n\u001b[1;32m     45\u001b[0m kwargs[\u001b[39m'\u001b[39m\u001b[39mpayload_type\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m payload_type\n\u001b[0;32m---> 46\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/Big data programming/newenv/lib/python3.10/site-packages/tweepy/api.py:1146\u001b[0m, in \u001b[0;36mAPI.search_tweets\u001b[0;34m(self, q, **kwargs)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[39m@pagination\u001b[39m(mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1053\u001b[0m \u001b[39m@payload\u001b[39m(\u001b[39m'\u001b[39m\u001b[39msearch_results\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1054\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msearch_tweets\u001b[39m(\u001b[39mself\u001b[39m, q, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1055\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"search_tweets(q, *, geocode, lang, locale, result_type, count, \\\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m \u001b[39m                     until, since_id, max_id, include_entities)\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[39m    .. _Twitter's documentation on the standard search API: https://developer.twitter.com/en/docs/twitter-api/v1/tweets/search/overview\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1146\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m   1147\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39msearch/tweets\u001b[39;49m\u001b[39m'\u001b[39;49m, endpoint_parameters\u001b[39m=\u001b[39;49m(\n\u001b[1;32m   1148\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mq\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mgeocode\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mlang\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mlocale\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mresult_type\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mcount\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m   1149\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39muntil\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39msince_id\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mmax_id\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39minclude_entities\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m   1150\u001b[0m         ), q\u001b[39m=\u001b[39;49mq, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m   1151\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/Big data programming/newenv/lib/python3.10/site-packages/tweepy/api.py:271\u001b[0m, in \u001b[0;36mAPI.request\u001b[0;34m(self, method, endpoint, endpoint_parameters, params, headers, json_payload, parser, payload_list, payload_type, post_data, files, require_auth, return_cursors, upload_api, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[39mraise\u001b[39;00m Unauthorized(resp)\n\u001b[1;32m    270\u001b[0m \u001b[39mif\u001b[39;00m resp\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m403\u001b[39m:\n\u001b[0;32m--> 271\u001b[0m     \u001b[39mraise\u001b[39;00m Forbidden(resp)\n\u001b[1;32m    272\u001b[0m \u001b[39mif\u001b[39;00m resp\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m404\u001b[39m:\n\u001b[1;32m    273\u001b[0m     \u001b[39mraise\u001b[39;00m NotFound(resp)\n",
      "\u001b[0;31mForbidden\u001b[0m: 403 Forbidden\n453 - You currently have access to a subset of Twitter API v2 endpoints and limited v1.1 endpoints (e.g. media post, oauth) only. If you need access to this endpoint, you may need a different access level. You can learn more here: https://developer.twitter.com/en/portal/product"
     ]
    }
   ],
   "source": [
    "consumer_key = 'RghnICqHJRxdBxMG6ecrSmldg'\n",
    "consumer_secret = '4XmQmA8wA4HugKRcoOU6fdcPqIc5paye3JhfTs7xIf88hAGnSg'\n",
    "access_token = '957706958475165696-M3xArvWOGd5JuvNhwpfc7fJsCoRJTf4'\n",
    "access_token_secret = 'IXtYKfxXReFgHVoRwZ7fl1vifAE45oBybkDhtFIJfe0La'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "keyword = 'Hello'\n",
    "num_tweets = 1\n",
    "\n",
    "tweets = tweepy.Cursor(api.search_tweets, q=keyword, tweet_mode='extended').items(num_tweets)\n",
    "\n",
    "for tweet in tweets:\n",
    "    print(f\"User: @{tweet.user.screen_name}\")\n",
    "    print(f\"Tweet: {tweet.full_text}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STOCKS API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Meta Data': {'1. Information': 'Intraday (5min) open, high, low, close prices and volume', '2. Symbol': 'IBM', '3. Last Refreshed': '2023-10-09 19:55:00', '4. Interval': '5min', '5. Output Size': 'Compact', '6. Time Zone': 'US/Eastern'}, 'Time Series (5min)': {'2023-10-09 19:55:00': {'1. open': '142.5000', '2. high': '142.5000', '3. low': '141.7800', '4. close': '141.7800', '5. volume': '99'}, '2023-10-09 19:50:00': {'1. open': '142.5000', '2. high': '142.5000', '3. low': '142.0300', '4. close': '142.0300', '5. volume': '12'}, '2023-10-09 19:45:00': {'1. open': '141.4500', '2. high': '141.4500', '3. low': '141.4500', '4. close': '141.4500', '5. volume': '2'}, '2023-10-09 19:40:00': {'1. open': '142.5000', '2. high': '142.5000', '3. low': '142.5000', '4. close': '142.5000', '5. volume': '3'}, '2023-10-09 19:15:00': {'1. open': '141.4500', '2. high': '141.4500', '3. low': '141.4500', '4. close': '141.4500', '5. volume': '25'}, '2023-10-09 19:00:00': {'1. open': '142.2000', '2. high': '142.2000', '3. low': '141.4500', '4. close': '141.4500', '5. volume': '338508'}, '2023-10-09 18:50:00': {'1. open': '142.1800', '2. high': '142.1800', '3. low': '142.1800', '4. close': '142.1800', '5. volume': '2'}, '2023-10-09 18:45:00': {'1. open': '141.4500', '2. high': '141.4500', '3. low': '141.4500', '4. close': '141.4500', '5. volume': '1'}, '2023-10-09 18:35:00': {'1. open': '142.5000', '2. high': '142.5000', '3. low': '141.4500', '4. close': '141.4500', '5. volume': '78'}, '2023-10-09 18:30:00': {'1. open': '142.2000', '2. high': '142.2000', '3. low': '142.0000', '4. close': '142.0000', '5. volume': '338519'}, '2023-10-09 18:10:00': {'1. open': '142.5000', '2. high': '142.5000', '3. low': '141.4500', '4. close': '141.4500', '5. volume': '7'}, '2023-10-09 18:05:00': {'1. open': '141.7800', '2. high': '141.7800', '3. low': '141.7800', '4. close': '141.7800', '5. volume': '3'}, '2023-10-09 17:55:00': {'1. open': '141.8800', '2. high': '141.8800', '3. low': '141.8700', '4. close': '141.8800', '5. volume': '24'}, '2023-10-09 17:40:00': {'1. open': '141.8800', '2. high': '141.8800', '3. low': '141.8800', '4. close': '141.8800', '5. volume': '4'}, '2023-10-09 17:25:00': {'1. open': '141.4500', '2. high': '141.4500', '3. low': '141.4500', '4. close': '141.4500', '5. volume': '69'}, '2023-10-09 17:15:00': {'1. open': '142.0600', '2. high': '142.0600', '3. low': '142.0600', '4. close': '142.0600', '5. volume': '1'}, '2023-10-09 17:10:00': {'1. open': '142.0000', '2. high': '142.0000', '3. low': '142.0000', '4. close': '142.0000', '5. volume': '1'}, '2023-10-09 17:00:00': {'1. open': '142.5000', '2. high': '142.5000', '3. low': '142.5000', '4. close': '142.5000', '5. volume': '5'}, '2023-10-09 16:55:00': {'1. open': '142.5000', '2. high': '142.5000', '3. low': '142.5000', '4. close': '142.5000', '5. volume': '1'}, '2023-10-09 16:45:00': {'1. open': '142.0100', '2. high': '142.0900', '3. low': '142.0000', '4. close': '142.0000', '5. volume': '15'}, '2023-10-09 16:35:00': {'1. open': '142.0800', '2. high': '142.0800', '3. low': '142.0800', '4. close': '142.0800', '5. volume': '25'}, '2023-10-09 16:30:00': {'1. open': '142.2800', '2. high': '142.2800', '3. low': '142.2000', '4. close': '142.2000', '5. volume': '7261'}, '2023-10-09 16:25:00': {'1. open': '142.0300', '2. high': '142.5000', '3. low': '142.0300', '4. close': '142.0800', '5. volume': '64'}, '2023-10-09 16:15:00': {'1. open': '142.2000', '2. high': '142.2000', '3. low': '142.2000', '4. close': '142.2000', '5. volume': '1'}, '2023-10-09 16:10:00': {'1. open': '142.2000', '2. high': '142.2000', '3. low': '142.2000', '4. close': '142.2000', '5. volume': '339809'}, '2023-10-09 16:05:00': {'1. open': '142.0000', '2. high': '142.0000', '3. low': '142.0000', '4. close': '142.0000', '5. volume': '10'}, '2023-10-09 16:00:00': {'1. open': '142.1900', '2. high': '142.2000', '3. low': '141.4500', '4. close': '142.0000', '5. volume': '708411'}, '2023-10-09 15:55:00': {'1. open': '141.9900', '2. high': '142.2100', '3. low': '141.9900', '4. close': '142.1900', '5. volume': '153854'}, '2023-10-09 15:50:00': {'1. open': '141.9500', '2. high': '142.0500', '3. low': '141.9200', '4. close': '141.9700', '5. volume': '68641'}, '2023-10-09 15:45:00': {'1. open': '141.9500', '2. high': '141.9700', '3. low': '141.8950', '4. close': '141.9600', '5. volume': '37496'}, '2023-10-09 15:40:00': {'1. open': '141.9400', '2. high': '142.0100', '3. low': '141.9300', '4. close': '141.9800', '5. volume': '29563'}, '2023-10-09 15:35:00': {'1. open': '141.9500', '2. high': '142.0100', '3. low': '141.9350', '4. close': '141.9450', '5. volume': '26975'}, '2023-10-09 15:30:00': {'1. open': '142.0200', '2. high': '142.0400', '3. low': '141.9500', '4. close': '141.9500', '5. volume': '30831'}, '2023-10-09 15:25:00': {'1. open': '142.0000', '2. high': '142.0300', '3. low': '141.9700', '4. close': '142.0100', '5. volume': '17645'}, '2023-10-09 15:20:00': {'1. open': '141.9700', '2. high': '142.0100', '3. low': '141.4200', '4. close': '141.9900', '5. volume': '19968'}, '2023-10-09 15:15:00': {'1. open': '141.8900', '2. high': '142.0150', '3. low': '141.8900', '4. close': '141.9900', '5. volume': '18318'}, '2023-10-09 15:10:00': {'1. open': '142.0000', '2. high': '142.0900', '3. low': '141.9250', '4. close': '141.9250', '5. volume': '20542'}, '2023-10-09 15:05:00': {'1. open': '141.9200', '2. high': '142.0000', '3. low': '141.9000', '4. close': '141.9800', '5. volume': '15128'}, '2023-10-09 15:00:00': {'1. open': '142.0000', '2. high': '142.0400', '3. low': '141.8700', '4. close': '141.9300', '5. volume': '29703'}, '2023-10-09 14:55:00': {'1. open': '142.0100', '2. high': '142.0800', '3. low': '141.9900', '4. close': '142.0000', '5. volume': '25096'}, '2023-10-09 14:50:00': {'1. open': '142.0200', '2. high': '142.0300', '3. low': '141.9650', '4. close': '142.0150', '5. volume': '15370'}, '2023-10-09 14:45:00': {'1. open': '142.0650', '2. high': '142.0650', '3. low': '141.9900', '4. close': '142.0200', '5. volume': '12011'}, '2023-10-09 14:40:00': {'1. open': '141.8900', '2. high': '142.0600', '3. low': '141.8800', '4. close': '142.0480', '5. volume': '14383'}, '2023-10-09 14:35:00': {'1. open': '141.8900', '2. high': '141.9000', '3. low': '141.8000', '4. close': '141.8800', '5. volume': '17837'}, '2023-10-09 14:30:00': {'1. open': '141.9800', '2. high': '142.0000', '3. low': '141.8700', '4. close': '141.8700', '5. volume': '17537'}, '2023-10-09 14:25:00': {'1. open': '141.9400', '2. high': '141.9900', '3. low': '141.8900', '4. close': '141.9800', '5. volume': '12550'}, '2023-10-09 14:20:00': {'1. open': '141.9500', '2. high': '141.9500', '3. low': '141.8700', '4. close': '141.9200', '5. volume': '13162'}, '2023-10-09 14:15:00': {'1. open': '141.9500', '2. high': '142.0180', '3. low': '141.9280', '4. close': '141.9280', '5. volume': '14966'}, '2023-10-09 14:10:00': {'1. open': '142.0100', '2. high': '142.0100', '3. low': '141.9100', '4. close': '141.9100', '5. volume': '17302'}, '2023-10-09 14:05:00': {'1. open': '141.9100', '2. high': '142.1220', '3. low': '141.8900', '4. close': '142.0250', '5. volume': '38066'}, '2023-10-09 14:00:00': {'1. open': '141.8900', '2. high': '141.9200', '3. low': '141.8500', '4. close': '141.9200', '5. volume': '16632'}, '2023-10-09 13:55:00': {'1. open': '141.8500', '2. high': '141.8900', '3. low': '141.8200', '4. close': '141.8750', '5. volume': '17135'}, '2023-10-09 13:50:00': {'1. open': '141.7700', '2. high': '141.8850', '3. low': '141.7400', '4. close': '141.8650', '5. volume': '20114'}, '2023-10-09 13:45:00': {'1. open': '141.7270', '2. high': '141.7900', '3. low': '141.7050', '4. close': '141.7500', '5. volume': '18404'}, '2023-10-09 13:40:00': {'1. open': '141.4750', '2. high': '141.7100', '3. low': '141.4700', '4. close': '141.7000', '5. volume': '20332'}, '2023-10-09 13:35:00': {'1. open': '141.4900', '2. high': '141.5100', '3. low': '141.4420', '4. close': '141.4750', '5. volume': '11091'}, '2023-10-09 13:30:00': {'1. open': '141.4600', '2. high': '141.5400', '3. low': '141.4450', '4. close': '141.5000', '5. volume': '17143'}, '2023-10-09 13:25:00': {'1. open': '141.3300', '2. high': '141.4500', '3. low': '141.3200', '4. close': '141.4300', '5. volume': '15022'}, '2023-10-09 13:20:00': {'1. open': '141.2700', '2. high': '141.3100', '3. low': '141.2000', '4. close': '141.3050', '5. volume': '14460'}, '2023-10-09 13:15:00': {'1. open': '141.2400', '2. high': '141.3100', '3. low': '141.2300', '4. close': '141.2500', '5. volume': '13341'}, '2023-10-09 13:10:00': {'1. open': '141.2000', '2. high': '141.2700', '3. low': '141.1500', '4. close': '141.2300', '5. volume': '13318'}, '2023-10-09 13:05:00': {'1. open': '141.1500', '2. high': '141.2200', '3. low': '141.1100', '4. close': '141.2000', '5. volume': '9767'}, '2023-10-09 13:00:00': {'1. open': '141.1600', '2. high': '141.2000', '3. low': '141.1100', '4. close': '141.1650', '5. volume': '10731'}, '2023-10-09 12:55:00': {'1. open': '141.1350', '2. high': '141.1700', '3. low': '141.0400', '4. close': '141.1600', '5. volume': '29660'}, '2023-10-09 12:50:00': {'1. open': '141.0900', '2. high': '141.1700', '3. low': '141.0900', '4. close': '141.1300', '5. volume': '12329'}, '2023-10-09 12:45:00': {'1. open': '140.9950', '2. high': '141.1200', '3. low': '140.9800', '4. close': '141.0710', '5. volume': '15274'}, '2023-10-09 12:40:00': {'1. open': '141.0700', '2. high': '141.0700', '3. low': '141.0000', '4. close': '141.0100', '5. volume': '19980'}, '2023-10-09 12:35:00': {'1. open': '141.0700', '2. high': '141.0800', '3. low': '141.0000', '4. close': '141.0750', '5. volume': '18001'}, '2023-10-09 12:30:00': {'1. open': '141.0600', '2. high': '141.1500', '3. low': '141.0500', '4. close': '141.0900', '5. volume': '11416'}, '2023-10-09 12:25:00': {'1. open': '141.2200', '2. high': '141.2400', '3. low': '141.0100', '4. close': '141.0600', '5. volume': '15144'}, '2023-10-09 12:20:00': {'1. open': '141.2370', '2. high': '141.2900', '3. low': '141.2000', '4. close': '141.2300', '5. volume': '17516'}, '2023-10-09 12:15:00': {'1. open': '141.2150', '2. high': '141.2900', '3. low': '141.2150', '4. close': '141.2250', '5. volume': '15372'}, '2023-10-09 12:10:00': {'1. open': '141.2300', '2. high': '141.2600', '3. low': '141.1700', '4. close': '141.2000', '5. volume': '13563'}, '2023-10-09 12:05:00': {'1. open': '141.0300', '2. high': '141.2450', '3. low': '141.0300', '4. close': '141.2220', '5. volume': '20486'}, '2023-10-09 12:00:00': {'1. open': '141.1100', '2. high': '141.1100', '3. low': '140.9900', '4. close': '141.0300', '5. volume': '21564'}, '2023-10-09 11:55:00': {'1. open': '141.0300', '2. high': '141.0900', '3. low': '140.9950', '4. close': '141.0900', '5. volume': '20271'}, '2023-10-09 11:50:00': {'1. open': '141.0500', '2. high': '141.0800', '3. low': '140.9750', '4. close': '141.0470', '5. volume': '22537'}, '2023-10-09 11:45:00': {'1. open': '141.2500', '2. high': '141.2500', '3. low': '141.0000', '4. close': '141.0300', '5. volume': '35144'}, '2023-10-09 11:40:00': {'1. open': '141.2800', '2. high': '141.2800', '3. low': '141.1900', '4. close': '141.2300', '5. volume': '15869'}, '2023-10-09 11:35:00': {'1. open': '141.2500', '2. high': '141.2750', '3. low': '141.1900', '4. close': '141.2300', '5. volume': '18892'}, '2023-10-09 11:30:00': {'1. open': '141.2500', '2. high': '141.3120', '3. low': '141.2200', '4. close': '141.2700', '5. volume': '19403'}, '2023-10-09 11:25:00': {'1. open': '141.1450', '2. high': '141.3200', '3. low': '141.1200', '4. close': '141.2550', '5. volume': '43543'}, '2023-10-09 11:20:00': {'1. open': '141.0900', '2. high': '141.1900', '3. low': '141.0500', '4. close': '141.1400', '5. volume': '18313'}, '2023-10-09 11:15:00': {'1. open': '141.1300', '2. high': '141.1450', '3. low': '141.0700', '4. close': '141.1200', '5. volume': '19112'}, '2023-10-09 11:10:00': {'1. open': '141.0700', '2. high': '141.1400', '3. low': '140.9000', '4. close': '141.1100', '5. volume': '36549'}, '2023-10-09 11:05:00': {'1. open': '141.0700', '2. high': '141.1100', '3. low': '140.9550', '4. close': '141.0610', '5. volume': '20133'}, '2023-10-09 11:00:00': {'1. open': '140.8300', '2. high': '141.1200', '3. low': '140.8300', '4. close': '141.0500', '5. volume': '31597'}, '2023-10-09 10:55:00': {'1. open': '140.7450', '2. high': '140.8800', '3. low': '140.7400', '4. close': '140.8600', '5. volume': '17802'}, '2023-10-09 10:50:00': {'1. open': '140.7700', '2. high': '140.8000', '3. low': '140.6800', '4. close': '140.7450', '5. volume': '24803'}, '2023-10-09 10:45:00': {'1. open': '141.0900', '2. high': '141.1100', '3. low': '140.7580', '4. close': '140.7600', '5. volume': '25059'}, '2023-10-09 10:40:00': {'1. open': '140.9500', '2. high': '141.1000', '3. low': '140.7660', '4. close': '141.1000', '5. volume': '46809'}, '2023-10-09 10:35:00': {'1. open': '140.9200', '2. high': '140.9900', '3. low': '140.9100', '4. close': '140.9400', '5. volume': '20945'}, '2023-10-09 10:30:00': {'1. open': '141.0700', '2. high': '141.0900', '3. low': '140.8900', '4. close': '140.9300', '5. volume': '32509'}, '2023-10-09 10:25:00': {'1. open': '141.0400', '2. high': '141.1000', '3. low': '140.9600', '4. close': '141.0800', '5. volume': '18849'}, '2023-10-09 10:20:00': {'1. open': '141.1850', '2. high': '141.2100', '3. low': '141.0100', '4. close': '141.0400', '5. volume': '20367'}, '2023-10-09 10:15:00': {'1. open': '141.0620', '2. high': '141.2100', '3. low': '141.0000', '4. close': '141.1800', '5. volume': '25387'}, '2023-10-09 10:10:00': {'1. open': '141.2300', '2. high': '141.2300', '3. low': '140.9500', '4. close': '141.0500', '5. volume': '33557'}, '2023-10-09 10:05:00': {'1. open': '141.2600', '2. high': '141.2900', '3. low': '141.0900', '4. close': '141.1950', '5. volume': '30532'}, '2023-10-09 10:00:00': {'1. open': '141.4600', '2. high': '141.5550', '3. low': '141.2700', '4. close': '141.3000', '5. volume': '28702'}, '2023-10-09 09:55:00': {'1. open': '141.3400', '2. high': '141.5400', '3. low': '141.2800', '4. close': '141.4700', '5. volume': '23046'}}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# replace the \"demo\" apikey below with your own key from https://www.alphavantage.co/support/#api-key\n",
    "url = 'https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol=IBM&interval=5min&apikey=demo'\n",
    "r = requests.get(url)\n",
    "data = r.json()\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL: Latest Price: 178.9500\n",
      "MSFT: Latest Price: 330.4500\n",
      "GOOGL: Latest Price: 138.5500\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "api_key = 'SJERGL47QPEJ09N3'\n",
    "symbols = ['AAPL', 'MSFT', 'GOOGL']\n",
    "stock_data = {}\n",
    "\n",
    "for symbol in symbols:\n",
    "    url = f'https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol={symbol}&interval=5min&apikey={api_key}'\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "        data = r.json()\n",
    "        stock_data[symbol] = data\n",
    "        latest_price = data['Time Series (5min)'][next(iter(data['Time Series (5min)']))]['4. close']\n",
    "        print(f\"{symbol}: Latest Price: {latest_price}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {symbol}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTC/USD: Exchange Rate: 27445.13000000\n",
      "ETH/USD: Exchange Rate: 1571.91000000\n",
      "DOGE/USD: Exchange Rate: 0.05876000\n"
     ]
    }
   ],
   "source": [
    "api_key = 'SJERGL47QPEJ09N3'\n",
    "cryptos = ['BTC', 'ETH', 'DOGE']\n",
    "crypto_data = {}\n",
    "\n",
    "for crypto in cryptos:\n",
    "    url = f'https://www.alphavantage.co/query?function=CURRENCY_EXCHANGE_RATE&from_currency={crypto}&to_currency=USD&apikey={api_key}'\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "        data = r.json()\n",
    "        crypto_data[crypto] = data\n",
    "        exchange_rate = data['Realtime Currency Exchange Rate']['5. Exchange Rate']\n",
    "        print(f\"{crypto}/USD: Exchange Rate: {exchange_rate}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {crypto}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing the data in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import requests\n",
    "\n",
    "# Initialize the SQLite database\n",
    "conn = sqlite3.connect('financial_data.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create tables for stocks and cryptocurrencies\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS stocks (\n",
    "                    symbol TEXT PRIMARY KEY,\n",
    "                    latest_price DECIMAL(10, 2)\n",
    "                )''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS cryptocurrencies (\n",
    "                    symbol TEXT PRIMARY KEY,\n",
    "                    exchange_rate DECIMAL(10, 2)\n",
    "                )''')\n",
    "\n",
    "# Define your API key and financial data\n",
    "api_key = 'YOUR_API_KEY'\n",
    "\n",
    "stocks = [\n",
    "    {'symbol': 'AAPL'},\n",
    "    {'symbol': 'MSFT'},\n",
    "    {'symbol': 'GOOGL'}\n",
    "]\n",
    "\n",
    "cryptos = [\n",
    "    {'symbol': 'BTC'},\n",
    "    {'symbol': 'ETH'},\n",
    "    {'symbol': 'LTC'}\n",
    "]\n",
    "\n",
    "# Retrieve and insert stock data\n",
    "for stock in stocks:\n",
    "    url = f'https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol={stock[\"symbol\"]}&interval=5min&apikey={api_key}'\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "        data = r.json()\n",
    "        latest_price = float(data['Time Series (5min)'][next(iter(data['Time Series (5min)']))]['4. close'])\n",
    "        cursor.execute('INSERT OR REPLACE INTO stocks (symbol, latest_price) VALUES (?, ?)', (stock[\"symbol\"], latest_price))\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {stock['symbol']}: {e}\")\n",
    "\n",
    "# Retrieve and insert cryptocurrency data\n",
    "for crypto in cryptos:\n",
    "    url = f'https://www.alphavantage.co/query?function=CURRENCY_EXCHANGE_RATE&from_currency={crypto[\"symbol\"]}&to_currency=USD&apikey={api_key}'\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "        data = r.json()\n",
    "        exchange_rate = float(data['Realtime Currency Exchange Rate']['5. Exchange Rate'])\n",
    "        cursor.execute('INSERT OR REPLACE INTO cryptocurrencies (symbol, exchange_rate) VALUES (?, ?)', (crypto[\"symbol\"], exchange_rate))\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {crypto['symbol']}: {e}\")\n",
    "\n",
    "# Commit changes and close the database connection\n",
    "conn.commit()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the data using pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'SJERGL47QPEJ09N3'\n",
    "symbols = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA']\n",
    "stock_data = []\n",
    "\n",
    "for symbol in symbols:\n",
    "    url = f'https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol={symbol}&interval=5min&apikey={api_key}'\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "        data = r.json()\n",
    "        latest_price = float(data['Time Series (5min)'][next(iter(data['Time Series (5min)']))]['4. close'])\n",
    "        stock_data.append({'Symbol': symbol, 'Latest_Price': latest_price})\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {symbol}: {e}\")\n",
    "\n",
    "df = pd.DataFrame(stock_data)\n",
    "df.to_csv('stock_prices.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEWS API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headline 1: NFL Week 5 takeaways: Everything feels over for the Patriots, Lions look legit, AFC South shakeout - CBS Sports\n",
      "Description 1: Will Brinson breaks down the biggest stories from Week 5 of the NFL season\n",
      "\n",
      "Headline 2: Travis Kelce’s Ex Maya Benberry Shares Cryptic Post Amid Taylor Swift Drama - Yahoo Entertainment\n",
      "Description 2: Kansas City Chiefs tight end Travis Kelce dated Maya Benberry for a few months in 2016 after she won his E! reality dating show, “Catching Kelce.” The two...\n",
      "\n",
      "Headline 3: Kevin McCarthy says he's willing to return as House speaker - The Washington Post\n",
      "Description 3: McCarthy made the comment as the House Republican conference prepared to meet for the first time since his ouster.\n",
      "\n",
      "Headline 4: During rare China trip, Schumer criticizes country's initial reaction to Hamas attack on Israel - POLITICO\n",
      "Description 4: The Senate majority leader also urged Beijing to use its relationship with Iran to not let the violence spread.\n",
      "\n",
      "Headline 5: Justice Department fights Trump effort to push Mar-a-Lago trial until after 2024 election - The Hill\n",
      "Description 5: The Justice Department is fighting an effort by former President Trump to delay his documents case until after the 2024 election, pushing back on claims the government hasn’t done its part to provide access to evidence. A recent motion seeking to delay the pr…\n",
      "\n"
     ]
    }
   ],
   "source": [
    "api_key = 'b33c03889a5a4a079278ea95444e4541'\n",
    "url = 'https://newsapi.org/v2/top-headlines'\n",
    "params = {'apiKey': api_key, 'country': 'us', 'pageSize': 5}\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    articles = response.json()['articles']\n",
    "    for idx, article in enumerate(articles, start=1):\n",
    "        print(f\"Headline {idx}: {article['title']}\\nDescription {idx}: {article['description']}\\n\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve news. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarizing the news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/joelmendonsa/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error summarizing article: Article `download()` failed with 429 Client Error: Unknown Error for url: https://thehill.com/regulation/court-battles/4245562-justice-department-fights-trump-effort-to-push-mar-a-lago-trial-until-after-2024-election/ on URL https://thehill.com/regulation/court-battles/4245562-justice-department-fights-trump-effort-to-push-mar-a-lago-trial-until-after-2024-election/\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from newspaper import Article\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "api_key = 'b33c03889a5a4a079278ea95444e4541'\n",
    "url = 'https://newsapi.org/v2/top-headlines'\n",
    "params = {'apiKey': api_key, 'country': 'us', 'pageSize': 5}\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    articles = response.json()['articles']\n",
    "    summaries = []\n",
    "\n",
    "    for article in articles:\n",
    "        try:\n",
    "            news_article = Article(article['url'])\n",
    "            news_article.download()\n",
    "            news_article.parse()\n",
    "            news_article.nlp()\n",
    "            summaries.append(news_article.summary)\n",
    "        except Exception as e:\n",
    "            print(f\"Error summarizing article: {e}\")\n",
    "\n",
    "    df = pd.DataFrame({'Summary': summaries})\n",
    "    df.to_csv('news_summaries.csv', index=False)\n",
    "else:\n",
    "    print(f\"Failed to retrieve news. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Summary\n",
      "0  It feels like something more coming on the hee...\n",
      "1  Kansas City Chiefs tight end Travis Kelce date...\n",
      "2  Rep. Kevin McCarthy (R-Calif.) said that the H...\n",
      "3  “We’re deeply saddened by the civilian casualt...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import sqlite3\n",
    "from newspaper import Article\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "api_key = 'b33c03889a5a4a079278ea95444e4541'\n",
    "url = 'https://newsapi.org/v2/top-headlines'\n",
    "params = {'apiKey': api_key, 'country': 'us', 'pageSize': 5}\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    articles = response.json()['articles']\n",
    "    summaries = []\n",
    "\n",
    "    for article in articles:\n",
    "        try:\n",
    "            news_article = Article(article['url'])\n",
    "            news_article.download()\n",
    "            news_article.parse()\n",
    "            news_article.nlp()\n",
    "            summaries.append(news_article.summary)\n",
    "        except Exception as e:\n",
    "            print(f\"Error summarizing article: {e}\")\n",
    "\n",
    "    # Create or connect to an SQLite database\n",
    "    conn = sqlite3.connect('news_summaries.db')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Create a table to store summaries\n",
    "    cursor.execute('''CREATE TABLE IF NOT EXISTS news_summaries (\n",
    "                        id INTEGER PRIMARY KEY,\n",
    "                        summary TEXT\n",
    "                    )''')\n",
    "\n",
    "    # Insert the summaries into the database\n",
    "    for summary in summaries:\n",
    "        cursor.execute('INSERT INTO news_summaries (summary) VALUES (?)', (summary,))\n",
    "\n",
    "    # Commit changes and close the database connection\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "else:\n",
    "    print(f\"Failed to retrieve news. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ecommerce API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product ID: 1\n",
      "Title: Fjallraven - Foldsack No. 1 Backpack, Fits 15 Laptops\n",
      "Price: $109.95\n",
      "Category: men's clothing\n",
      "---\n",
      "Product ID: 2\n",
      "Title: Mens Casual Premium Slim Fit T-Shirts \n",
      "Price: $22.3\n",
      "Category: men's clothing\n",
      "---\n",
      "Product ID: 3\n",
      "Title: Mens Cotton Jacket\n",
      "Price: $55.99\n",
      "Category: men's clothing\n",
      "---\n",
      "Product ID: 4\n",
      "Title: Mens Casual Slim Fit\n",
      "Price: $15.99\n",
      "Category: men's clothing\n",
      "---\n",
      "Product ID: 5\n",
      "Title: John Hardy Women's Legends Naga Gold & Silver Dragon Station Chain Bracelet\n",
      "Price: $695\n",
      "Category: jewelery\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "api_url = \"https://fakestoreapi.com/products\"\n",
    "num_products = 5\n",
    "\n",
    "try:\n",
    "    response = requests.get(api_url)\n",
    "    if response.status_code == 200:\n",
    "        products = response.json()[:num_products]\n",
    "        for product in products:\n",
    "            print(f\"Product ID: {product['id']}\")\n",
    "            print(f\"Title: {product['title']}\")\n",
    "            print(f\"Price: ${product['price']}\")\n",
    "            print(f\"Category: {product['category']}\")\n",
    "            print(\"---\")\n",
    "    else:\n",
    "        print(f\"Failed to retrieve products. Status code: {response.status_code}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOCIAL MEDIA API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Request failed with status code: 400\n"
     ]
    }
   ],
   "source": [
    "user_id = 'Savio Mendonsa'\n",
    "\n",
    "# Replace 'access_token' with a valid access token\n",
    "access_token = 'EAAKIjkVe4IsBO51ZA2HluVulDUKpFp40PY3HC0bhMWrYLjOZBi7B80zGL8KsdgIOirevXOYukvLK99nKHYZCuhGo5fjbpKGAINhqfmbWkCYUyllE5ZAp7H6lCNcdr2w80nPY5C72PlJTqzhSTgdmtUJckTQowvoTwJpckL1kQ50Qq0lbSSH7KkNmXiZAOVWTEsN2CO6KfQ3GGpGUD7IW9MfvZA2cMAw48xjnaZCZBD0WacRMGxHfHo8rNjktvfboPP4ZD'\n",
    "\n",
    "# Define the API endpoint to fetch the user's public profile\n",
    "api_url = f'https://graph.facebook.com/vX.X/{user_id}?fields=id,name,email,picture&access_token={access_token}'\n",
    "\n",
    "# Make the GET request to the API\n",
    "response = requests.get(api_url)\n",
    "\n",
    "# Check the status code of the response\n",
    "if response.status_code == 200:\n",
    "    # Request was successful\n",
    "    user_data = response.json()\n",
    "    print(\"User Profile Data:\")\n",
    "    print(user_data)\n",
    "else:\n",
    "    # Request failed\n",
    "    print(f\"API Request failed with status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NASA API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Astronomy Picture of the Day (APOD):\n",
      "Title: NGC 1097: Spiral Galaxy with Supernova\n",
      "Date: 2023-10-11\n",
      "Explanation: What's happening in the lower arm of this spiral galaxy? A supernova. Last month, supernova SN 2023rve was discovered with UAE's Al-Khatim Observatory and later found to be consistent with the death explosion of a massive star, possibly leaving behind a black hole. Spiral galaxy NGC 1097 is a relatively close 45 million light years away and visible with a small telescope toward the southern constellation of the Furnace (Fornax).  The galaxy is notable not only for its picturesque spiral arms, but also for faint jets consistent with ancient star streams left over from a galactic collision -- possibly with the small galaxy seen between its arms on the lower left. The featured image highlights the new supernova by blinking between two exposures taken several months apart. Finding supernovas in nearby galaxies can be important in determining the scale and expansion rate of our entire universe -- a topic currently of unexpected tension and much debate.    APOD editor to speak: in Houghton, Michigan on Thursday, October 12 at 6 pm\n",
      "URL: https://apod.nasa.gov/apod/image/2310/Ngc1097wSn_Miller_1008.gif\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "api_key = 'zoNmtv6LlsfgVBLHVfEjX0dsaF9bikIhZT7Jrubb'\n",
    "apod_url = f'https://api.nasa.gov/planetary/apod?api_key={api_key}'\n",
    "\n",
    "try:\n",
    "    response = requests.get(apod_url)\n",
    "    if response.status_code == 200:\n",
    "        apod_data = response.json()\n",
    "        print(\"Astronomy Picture of the Day (APOD):\")\n",
    "        print(f\"Title: {apod_data['title']}\")\n",
    "        print(f\"Date: {apod_data['date']}\")\n",
    "        print(f\"Explanation: {apod_data['explanation']}\")\n",
    "        print(f\"URL: {apod_data['url']}\")\n",
    "    else:\n",
    "        print(f\"API Request failed with status code: {response.status_code}\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    # An error occurred during the request\n",
    "    print(f\"An error occurred: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "api_key = 'your_api_key_here'\n",
    "apod_url = f'https://api.nasa.gov/planetary/apod?api_key={api_key}'\n",
    "response = requests.get(apod_url)\n",
    "if response.status_code == 200:\n",
    "    apod_data = response.json()\n",
    "    print(apod_data)\n",
    "else:\n",
    "    print(f\"API Request failed with status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing in sqllite3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import sqlite3\n",
    "\n",
    "# Replace 'your_api_key_here' with your NASA API key\n",
    "api_key = 'your_api_key_here'\n",
    "apod_url = f'https://api.nasa.gov/planetary/apod?api_key={api_key}'\n",
    "\n",
    "# Make a request to the APOD API\n",
    "response = requests.get(apod_url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    apod_data = response.json()\n",
    "\n",
    "    # Establish a connection to an SQLite database (or use another database of your choice)\n",
    "    conn = sqlite3.connect('civic_analysis.db')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Create a table to store APOD data\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS apod_data (\n",
    "            title TEXT,\n",
    "            date TEXT,\n",
    "            explanation TEXT,\n",
    "            url TEXT\n",
    "        )\n",
    "    ''')\n",
    "\n",
    "    # Insert the APOD data into the database\n",
    "    cursor.execute('''\n",
    "        INSERT INTO apod_data (title, date, explanation, url)\n",
    "        VALUES (?, ?, ?, ?)\n",
    "    ''', (apod_data['title'], apod_data['date'], apod_data['explanation'], apod_data['url']))\n",
    "\n",
    "    # Commit the changes and close the database connection\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "else:\n",
    "    print(f\"API Request failed with status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing in MYSQL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import mysql.connector\n",
    "\n",
    "# Replace 'your_api_key_here' with your NASA API key\n",
    "api_key = 'your_api_key_here'\n",
    "apod_url = f'https://api.nasa.gov/planetary/apod?api_key={api_key}'\n",
    "\n",
    "# Make a request to the APOD API\n",
    "response = requests.get(apod_url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    apod_data = response.json()\n",
    "\n",
    "    # Establish a connection to your MySQL database\n",
    "    conn = mysql.connector.connect(\n",
    "        host='your_mysql_host',\n",
    "        user='your_mysql_user',\n",
    "        password='your_mysql_password',\n",
    "        database='your_database_name'\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Create a table to store APOD data\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS apod_data (\n",
    "            id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "            title VARCHAR(255),\n",
    "            date VARCHAR(20),\n",
    "            explanation TEXT,\n",
    "            url VARCHAR(255)\n",
    "        )\n",
    "    ''')\n",
    "\n",
    "    # Insert the APOD data into the database\n",
    "    insert_query = '''\n",
    "        INSERT INTO apod_data (title, date, explanation, url)\n",
    "        VALUES (%s, %s, %s, %s)\n",
    "    '''\n",
    "    cursor.execute(insert_query, (apod_data['title'], apod_data['date'], apod_data['explanation'], apod_data['url']))\n",
    "\n",
    "    # Commit the changes and close the database connection\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "else:\n",
    "    print(f\"API Request failed with status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHALLENGE 1 NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Description: Your perfect pack for everyday use and walks in the forest. Stash your laptop (up to 15 inches) in the padded sleeve, your everyday\n",
      "Product Description: Slim-fitting style, contrast raglan long sleeve, three-button henley placket, light weight & soft fabric for breathable and comfortable wearing. And Solid stitched shirts with round neck made for durability and a great fit for casual fashion wear and diehard baseball fans. The Henley style round neckline includes a three-button placket.\n",
      "Product Description: great outerwear jackets for Spring/Autumn/Winter, suitable for many occasions, such as working, hiking, camping, mountain/rock climbing, cycling, traveling or other outdoors. Good gift choice for you or your family member. A warm hearted love to Father, husband or son in this thanksgiving or Christmas Day.\n",
      "Product Description: The color could be slightly different between on the screen and in practice. / Please note that body builds vary by person, therefore, detailed size information should be reviewed below on the product description.\n",
      "Product Description: From our Legends Collection, the Naga was inspired by the mythical water dragon that protects the ocean's pearl. Wear facing inward to be bestowed with love and abundance, or outward for protection.\n",
      "Product Description: Satisfaction Guaranteed. Return or exchange any order within 30 days.Designed and sold by Hafeez Center in the United States. Satisfaction Guaranteed. Return or exchange any order within 30 days.\n",
      "Product Description: Classic Created Wedding Engagement Solitaire Diamond Promise Ring for Her. Gifts to spoil your love more for Engagement, Wedding, Anniversary, Valentine's Day...\n",
      "Product Description: Rose Gold Plated Double Flared Tunnel Plug Earrings. Made of 316L Stainless Steel\n",
      "Product Description: USB 3.0 and USB 2.0 Compatibility Fast data transfers Improve PC Performance High Capacity; Compatibility Formatted NTFS for Windows 10, Windows 8.1, Windows 7; Reformatting may be required for other operating systems; Compatibility may vary depending on user’s hardware configuration and operating system\n",
      "Product Description: Easy upgrade for faster boot up, shutdown, application load and response (As compared to 5400 RPM SATA 2.5” hard drive; Based on published specifications and internal benchmarking tests using PCMark vantage scores) Boosts burst write performance, making it ideal for typical PC workloads The perfect balance of performance and reliability Read/write speeds of up to 535MB/s/450MB/s (Based on internal testing; Performance may vary depending upon drive capacity, host device, OS and application.)\n",
      "Product Description: 3D NAND flash are applied to deliver high transfer speeds Remarkable transfer speeds that enable faster bootup and improved overall system performance. The advanced SLC Cache Technology allows performance boost and longer lifespan 7mm slim design suitable for Ultrabooks and Ultra-slim notebooks. Supports TRIM command, Garbage Collection technology, RAID, and ECC (Error Checking & Correction) to provide the optimized performance and enhanced reliability.\n",
      "Product Description: Expand your PS4 gaming experience, Play anywhere Fast and easy, setup Sleek design with high capacity, 3-year manufacturer's limited warranty\n",
      "Product Description: 21. 5 inches Full HD (1920 x 1080) widescreen IPS display And Radeon free Sync technology. No compatibility for VESA Mount Refresh Rate: 75Hz - Using HDMI port Zero-frame design | ultra-thin | 4ms response time | IPS panel Aspect ratio - 16: 9. Color Supported - 16. 7 million colors. Brightness - 250 nit Tilt angle -5 degree to 15 degree. Horizontal viewing angle-178 degree. Vertical viewing angle-178 degree 75 hertz\n",
      "Product Description: 49 INCH SUPER ULTRAWIDE 32:9 CURVED GAMING MONITOR with dual 27 inch screen side by side QUANTUM DOT (QLED) TECHNOLOGY, HDR support and factory calibration provides stunningly realistic and accurate color and contrast 144HZ HIGH REFRESH RATE and 1ms ultra fast response time work to eliminate motion blur, ghosting, and reduce input lag\n",
      "Product Description: Note:The Jackets is US standard size, Please choose size as your usual wear Material: 100% Polyester; Detachable Liner Fabric: Warm Fleece. Detachable Functional Liner: Skin Friendly, Lightweigt and Warm.Stand Collar Liner jacket, keep you warm in cold weather. Zippered Pockets: 2 Zippered Hand Pockets, 2 Zippered Pockets on Chest (enough to keep cards or keys)and 1 Hidden Pocket Inside.Zippered Hand Pockets and Hidden Pocket keep your things secure. Humanized Design: Adjustable and Detachable Hood and Adjustable cuff to prevent the wind and water,for a comfortable fit. 3 in 1 Detachable Design provide more convenience, you can separate the coat and inner as needed, or wear it together. It is suitable for different season and help you adapt to different climates\n",
      "Product Description: 100% POLYURETHANE(shell) 100% POLYESTER(lining) 75% POLYESTER 25% COTTON (SWEATER), Faux leather material for style and comfort / 2 pockets of front, 2-For-One Hooded denim style faux leather jacket, Button detail on waist / Detail stitching at sides, HAND WASH ONLY / DO NOT BLEACH / LINE DRY / DO NOT IRON\n",
      "Product Description: Lightweight perfet for trip or casual wear---Long sleeve with hooded, adjustable drawstring waist design. Button and zipper front closure raincoat, fully stripes Lined and The Raincoat has 2 side pockets are a good size to hold all kinds of things, it covers the hips, and the hood is generous but doesn't overdo it.Attached Cotton Lined Hood with Adjustable Drawstrings give it a real styled look.\n",
      "Product Description: 95% RAYON 5% SPANDEX, Made in USA or Imported, Do Not Bleach, Lightweight fabric with great stretch for comfort, Ribbed on sleeves and neckline / Double stitching on bottom hem\n",
      "Product Description: 100% Polyester, Machine wash, 100% cationic polyester interlock, Machine Wash & Pre Shrunk for a Great Fit, Lightweight, roomy and highly breathable with moisture wicking fabric which helps to keep moisture away, Soft Lightweight Fabric with comfortable V-neck collar and a slimmer fit, delivers a sleek, more feminine silhouette and Added Comfort\n",
      "Product Description: 95%Cotton,5%Spandex, Features: Casual, Short Sleeve, Letter Print,V-Neck,Fashion Tees, The fabric is soft and has some stretch., Occasion: Casual/Office/Beach/School/Home/Street. Season: Spring,Summer,Autumn,Winter.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "api_url = 'https://fakestoreapi.com/products'\n",
    "\n",
    "response = requests.get(api_url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    for product in data:\n",
    "        print(f\"Product Description: {product['description']}\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve data. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/joelmendonsa/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/joelmendonsa/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product descriptions have been analyzed and saved to 'product_descriptions.csv'.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "api_url = 'https://fakestoreapi.com/products'\n",
    "response = requests.get(api_url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    descriptions = []\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    for product in data:\n",
    "        words = word_tokenize(product['description'])\n",
    "        words = [word.lower() for word in words if word.isalpha() and word.lower() not in stop_words]\n",
    "        descriptions.append(' '.join(words))\n",
    "\n",
    "    df = pd.DataFrame({'Description': descriptions})\n",
    "    df.to_csv('product_descriptions.csv', index=False)\n",
    "    print(\"Product descriptions have been analyzed and saved to 'product_descriptions.csv'.\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve data. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing the data using MYSQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import mysql.connector\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Replace these with your MySQL database details\n",
    "db_host = 'your_database_host'\n",
    "db_user = 'your_database_user'\n",
    "db_password = 'your_database_password'\n",
    "db_name = 'your_database_name'\n",
    "\n",
    "# Establish a connection to the MySQL database\n",
    "conn = mysql.connector.connect(host=db_host, user=db_user, password=db_password, database=db_name)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create a table to store the descriptions if it doesn't exist\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS product_descriptions (\n",
    "    id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    description TEXT\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(create_table_query)\n",
    "\n",
    "api_url = 'https://fakestoreapi.com/products'\n",
    "response = requests.get(api_url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    descriptions = []\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    for product in data:\n",
    "        words = word_tokenize(product['description'])\n",
    "        words = [word.lower() for word in words if word.isalpha() and word.lower() not in stop_words]\n",
    "        cleaned_description = ' '.join(words)\n",
    "        descriptions.append((cleaned_description,))\n",
    "\n",
    "    # Insert the data into the MySQL database\n",
    "    insert_query = \"INSERT INTO product_descriptions (description) VALUES (%s)\"\n",
    "    cursor.executemany(insert_query, descriptions)\n",
    "    conn.commit()\n",
    "\n",
    "    print(\"Product descriptions have been analyzed and saved to the MySQL database.\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve data. Status code: {response.status_code}\")\n",
    "\n",
    "# Close the database connection\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOMALY DETECTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve order data. Status code: 404\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def fetch_order_data():\n",
    "    api_url = 'https://fakestoreapi.com/orders'\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(api_url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"Failed to retrieve order data. Status code: {response.status_code}\")\n",
    "            return []\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return []\n",
    "\n",
    "def process_order_data(orders):\n",
    "    for order in orders:\n",
    "        order_id = order['id']\n",
    "        user_name = order['user']['username']\n",
    "        total_price = order['total']\n",
    "        print(f\"Order ID: {order_id}\")\n",
    "        print(f\"User Name: {user_name}\")\n",
    "        print(f\"Total Price: ${total_price}\")\n",
    "        print(\"-------------\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    order_data = fetch_order_data()\n",
    "\n",
    "    if order_data:\n",
    "        process_order_data(order_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
